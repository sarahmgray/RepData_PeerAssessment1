getwd()
getwd()
q()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="./data/microdata.csv", method="curl")
if(!file.exists("data")) {
dir.create("data")
}
download.file(fileUrl, destfile="./data/microdata.csv", method="curl")
download.file(fileUrl, destfile="./data/microdata.csv")
microData <- read.table("./data/microdata.csv", sep=",", header=TRUE)
sum(!is.na(microData$VAL[microData$VAL==24]))
microdata$FES
microData$FES
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="./data/nga.xlsx", method="curl")
download.file(fileUrl, destfile="./data/nga.xlsx")
dateDownloaded <- date()
library(xlsx)
download.file(fileUrl, destfile="./data/nga.xlsx", mode='wb')
library(xlsx)
install.packages("rJava")
install.packages("xlsxjars")
install.packages("xlsx")
library(rJava)
library(xlsxjars)
library(xlsx)
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx(".data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
dat <- read.xlsx(".data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
dat <- read.xlsx("./data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
sum(dat$ZIP*dat$Ext, na.rm=T)
sum(dat$Zip*dat$Ext,na.rm=T)
library(xlsx)
fileURL <-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileURL, destfile="./data/nga.xlsx", method="curl")
download.file(fileUrl, destfile="./data/nga.xlsx", method="curl")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile="./data/nga.xlsx", method="curl")
if(!file.exists("data")) {
dir.create("data")
}
download.file(fileUrl, destfile="./data/nga.xlsx", method="curl")
download.file(fileUrl, destfile="./data/nga.xlsx")
dateDownloaded <- date()
library(xlsx)
colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("./data/nga.xlsx", sheetIndex=1, header=TRUE, colIndex=colIndex, rowIndex=rowIndex)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
library(xmlTreeParse)
library(XML)
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv "
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="./data/microdata3.csv", method="curl")
download.file(fileUrl, destfile="./data/microdata3.csv")
DT <- fread("./data/microdata3.csv")
library(data.table)
DT <- fread("./data/microdata3.csv")
file.info("./data/microdata3.csv")$size
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
library(sqldf)
extsts(Rtools)
install.packages("sql")
install.packages(c("sqldf", "sqlutils", "RJDBC", "RODBC"))
exists(Rtools)
install.packages("Rtools")
?RTools
??Rtools
?Rtools
install.packages(httpuv)
install.packages("httpuv")
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode[1:9]
?nchar
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
read.fwf(https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for)
read.fwf(https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for, header=TRUE)
read.fwf(https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for, widths=61, header=false, sep" ", skip=4)
req <- GET("https://api.github.com/repos", config(token = github_token))
> stop_for_status(req)
> content(req)
> BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
req <- GET("https://api.github.com/repos", config(token = github_token))
> stop_for_status(req)
> content(req)
> BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
data <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", header = TRUE)
> file_name <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
> df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
> sum(df[, 4])
req <- GET("https://api.github.com/repos", config(token = github_token))
stop_for_status(req)
content(req)
BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
data <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", header = TRUE)
file_name <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
sum(df[, 4])
library(swirl)
ls()
rm(list=ls())
swirl()
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = false)
mydf <- read.csv(file = "path2csv", stringsAsFactors = false)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
pacageVersion("dplyr")
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US"| country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, "size:ip_id"")
cran2 <- select(cran, "size:ip_id")
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2,(desc(ip_id)))
arrange(cran2,(desc(ip_id))
arrange(cran2, (desc(ip_id))
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size+1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df("mydf")
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- groupby(cran, package)
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_cum$unique, probs = 0.99)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
view(top_unique)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
result3
View(result3)
cran %>%
select() %>%
ip_id
country
package
size
print
cran %>%
select(ip_id, country, package, size) %>%
print
submit()
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(data=students2, key=sex_class, value=count)
res <- gather(data=students2, key=sex_class, value=count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
sumbit()
submit()
students3
submit()
submit()
submit()
submit()
submit()
submit()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
q()
setwd("C:/Users/SA-Sgray/RepData_PeerAssessment1")
